family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(r0=cor(pred0, y_linear[!is.train]),r1=cor(pred,y_linear[!is.train]))
})
sapply(rep(seq(0.5,0.9,0.05),5), function(prob) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=probe,r0=cor(pred0, y_linear[!is.train]),r1=cor(pred,y_linear[!is.train]))
})
sapply(rep(seq(0.5,0.9,0.05),5), function(prob) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,r0=cor(pred0, y_linear[!is.train]),r1=cor(pred,y_linear[!is.train]))
})
ret <- sapply(seq(0.5,0.9,0.05), function(prob) {
c(
prob=prob,
rowMeans(sapply(1:5, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})))
})
ret
ret <- sapply(seq(0.5,0.9,0.05), function(prob) {
r <- sapply(1:5, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})
c(prob=prob,rowMeans(r,na.rm=T))
})
ret
t(ret)
plot(ret[,2], ret[,3])
plot(ret[,2], ret[,3])
ret[1:5,]
plot(ret[,2], ret[,3])
ret <- t(ret)
plot(ret[,"r0"],ret[,"r1"])
ret <- t(ret)
ret <- t(ret)
plot(ret[,"prob"],ret[,"r1"],pch=19,col="red")
points(ret[,"prob"],ret[,"r0"],pch=19,col="blue")
plot(ret[,"prob"],ret[,"r1"],pch=19,col="red")
points(ret[,"prob"],ret[,"r0"],pch=19,col="blue")
plot(ret[,"prob"],ret[,"r1"],pch=19,col="red")
point(ret[,"prob"],ret[,"r0"],pch=19,col="blue")
plot(ret[,"prob"],ret[,"r1"],pch=19,col="red")
points(ret[,"prob"],ret[,"r0"],pch=19,col="blue")
plot(ret[,"prob"],ret[,"r1"],pch=19,col="red",ylim=range(ret[,c("r0","r1")]))
points(ret[,"prob"],ret[,"r0"],pch=19,col="blue")
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind(.))
}) %>% do.call(rbind(.))
3 %>% print()
R.version
library(tidyr)
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind(.))
}) %>% do.call(rbind(.))
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind, .)
}) %>% do.call(rbind, .)
}
}
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind, .)
}) %>% do.call(rbind, .)
ret <- t(ret)
ret[1:5,]
class(ret)
dim(ret)
ret <- t(ret)
ret[1:5,]
ret <- data.frame(r="r0",ret[,c("prob","r0")], r="r1",ret[,c("prob","r1")])
dim(ret)
ret[1:5,]
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind, .)
}) %>% do.call(rbind, .)
ret <- cbind(
data.frame(r="r0",ret[,c("prob","r0")]),
data.frame(r="r1",ret[,c("prob","r1")]))
dim(ret)
ret <- lapply(seq(0.5,0.9,0.05), function(prob) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(0.49,0.51), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prob=prob,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind, .)
}) %>% do.call(rbind, .)
ret <- rbind(
data.frame(r="r0",ret[,c("prob","r0")]),
data.frame(r="r1",ret[,c("prob","r1")]))
class(ret)
dim(ret)
ret[1:5,]
ret <- rbind(
data.frame(model="base",prop=ret[,"prob"],r=ret[,"r0"]),
data.frame(model="hier",prop=ret[,"prob"],r=ret[,"r1"]))
ret[1:5,]
dim(ret)
boxplot(r ~ prop + model, data=ret)
boxplot(r ~ model+prop, data=ret)
boxplot(r ~ model+prop, data=ret)
boxplot(r ~ model+prop, data=ret)
ret <- lapply(seq(0.5,0.9,0.05), function(prop) {
lapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(1-prop,prop), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prop=prop,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
}) %>% do.call(rbind, .)
}) %>% do.call(rbind, .)
rlapply <- function(...) do.call(rbind, lapply(...))
ret <- rlapply(seq(0.5,0.9,0.05), function(prop) {
rlapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(1-prop,prop), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prop=prop,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})
})
ret <- rbind(
data.frame(model="base",prop=ret[,"prob"],r=ret[,"r0"]),
data.frame(model="hier",prop=ret[,"prob"],r=ret[,"r1"]))
ret <- rbind(
data.frame(model="base",prop=ret[,"prop"],r=ret[,"r0"]),
data.frame(model="hier",prop=ret[,"prop"],r=ret[,"r1"]))
ggplot(data=ret, mapping=aes(x=prop, y=r, fill=factor(model))) +
geom_boxplot()
library(ggplot)
library(ggplot2)
ggplot(data=ret, mapping=aes(x=prop, y=r, fill=factor(model))) +
geom_boxplot()
dim(ret)
dim(na.omit(ret))
ret <- na.omit(ret)
library(ggplot2)
ggplot(data=ret, mapping=aes(x=prop, y=r, fill=factor(model))) +
geom_boxplot()
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot()
ret$model[ret$model == "hier"] <- "hierarchical"
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot()
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot() +
xlab("proportion training") +
ylab("R")
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot() +
xlab("proportion training") +
ylab("performance (R)")
ret <- rlapply(seq(0.5,0.9,0.05), function(prop) {
rlapply(1:20, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(1-prop,prop), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prop=prop,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})
})
ret <- rlapply(seq(0.3,0.8,0.05), function(prop) {
rlapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(1-prop,prop), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prop=prop,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})
})
ret <- rbind(
data.frame(model="base",prop=ret[,"prop"],r=ret[,"r0"]),
data.frame(model="hierarchical",prop=ret[,"prop"],r=ret[,"r1"]))
ret <- na.omit(ret)
library(ggplot2)
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot() +
xlab("proportion training") +
ylab("performance (R)")
ret <- rlapply(seq(0.1,0.9,0.1), function(prop) {
rlapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(1-prop,prop), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0)    ## ridge
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prop=prop,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})
})
ret <- rbind(
data.frame(model="base",prop=ret[,"prop"],r=ret[,"r0"]),
data.frame(model="hierarchical",prop=ret[,"prop"],r=ret[,"r1"]))
ret <- na.omit(ret)
library(ggplot2)
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot() +
xlab("proportion training") +
ylab("performance (R)")
options(warn)
options("warn")
options()$warn
names(options())
suppressWarnings({
ret <- rlapply(seq(0.1,0.9,0.1), function(prop) {
rlapply(1:10, function(i) {
is.train <- sample(c(F,T), length(y_linear), prob=c(1-prop,prop), replace=T)
model0 <- tune_xrnet(
x = x_linear[is.train,],
y = y_linear[is.train],
family = "gaussian",
penalty_main = define_penalty(0)
)
pred0 <- predict(model0, newdata=x_linear[!is.train,], type="response")
model <- tune_xrnet(
x = x_linear[is.train,], ## 50 features
y = y_linear[is.train],  ## variable of interest
external = ext_linear,   ## 5 external features for 50 features (50x5)
family = "gaussian",   ## outcome variable is numerical
penalty_main = define_penalty(0),    ## ridge
penalty_external = define_penalty(1) ## lasso
)
pred <- predict(model, newdata=x_linear[!is.train,], type="response")
c(prop=prop,
r0=cor(pred0, y_linear[!is.train],use="p"),
r1=cor(pred,y_linear[!is.train],use="p"))
})
})
})
ret <- rbind(
data.frame(model="base",prop=ret[,"prop"],r=ret[,"r0"]),
data.frame(model="hierarchical",prop=ret[,"prop"],r=ret[,"r1"]))
ret <- na.omit(ret)
library(ggplot2)
ggplot(data=ret, mapping=aes(x=as.character(prop), y=r, fill=factor(model))) +
geom_boxplot() +
xlab("proportion training") +
ylab("performance (R)")
